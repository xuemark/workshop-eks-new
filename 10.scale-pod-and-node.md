
# 10. Scale pod and node

## ENV
- ALB URL for myapp
```
ALB_URL=$(kubectl get ingress -o json| jq -r '.items[0].status.loadBalancer.ingress[0].hostname')
```

## Configure HPA
### 1. manually scale pod
```
kubectl scale deployment/myapp-deployment --replicas=15 
kubectl get pod -o wide
```
Check EC2>LOAD BALANCING>Target Group>Targets

### 2. check pod status
There are N pod in Pending status.
```
kubectl get pod
kubectl get pod -o json | jq -r '.items[] | select(.status.phase=="Pending")' | jq -r '.metadata.name'
kubectl get events
```
### 3. scale node group
scale node instance to 3
```
eksctl scale nodegroup --cluster=${CLUSTER_NAME} --name=${NODEGROUP_NAME} --region=${AWS_REGION} --nodes=3 --nodes-min=3

kubectl get node
```
### 4. check pod status
All pods are in Running status.
```
kubectl get pod -o wide
```

### 5. create HPA
scale down pod
```
kubectl scale --replicas=1 deployment/myapp-deployment
kubectl get pod -o wide
```
install HPA
```
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml

kubectl get deployment metrics-server -n kube-system
```

### 6. set limit for pod
```
kubectl set resources deployment myapp-deployment --limits=cpu=200m,memory=256Mi
```

### 7. set autoscale policy
```
kubectl autoscale deployment myapp-deployment --cpu-percent=30 --min=1 --max=30
```

### 8. monitor HPA
```
kubectl top pod
kubectl get hpa --watch
```

### 9. load test
open another session, run load test
```
ALB_URL=$(kubectl get ingress -o json| jq -r '.items[0].status.loadBalancer.ingress[0].hostname')
ab -c 10 -n 2000000 http://${ALB_URL}/index.jsp
```
### 10. stop load
- ctrl-c to shut down ab test, pods will scale in to 1.

## Configure CA

### 1. create cluster autoscaler

#### make ca yaml
```
cat <<EOF > cluster-autoscaler-autodiscover.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["events", "endpoints"]
    verbs: ["create", "patch"]
  - apiGroups: [""]
    resources: ["pods/eviction"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["pods/status"]
    verbs: ["update"]
  - apiGroups: [""]
    resources: ["endpoints"]
    resourceNames: ["cluster-autoscaler"]
    verbs: ["get", "update"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["watch", "list", "get", "update"]
  - apiGroups: [""]
    resources:
      - "pods"
      - "services"
      - "replicationcontrollers"
      - "persistentvolumeclaims"
      - "persistentvolumes"
    verbs: ["watch", "list", "get"]
  - apiGroups: ["extensions"]
    resources: ["replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["watch", "list"]
  - apiGroups: ["apps"]
    resources: ["statefulsets", "replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses", "csinodes"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["batch", "extensions"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["create"]
  - apiGroups: ["coordination.k8s.io"]
    resourceNames: ["cluster-autoscaler"]
    resources: ["leases"]
    verbs: ["get", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create","list","watch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["cluster-autoscaler-status", "cluster-autoscaler-priority-expander"]
    verbs: ["delete", "get", "update", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '8085'
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
        - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.17.3
          name: cluster-autoscaler
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 100m
              memory: 300Mi
          command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/xxx
            - --balance-similar-node-groups
            - --skip-nodes-with-system-pods=false
          volumeMounts:
            - name: ssl-certs
              mountPath: /etc/ssl/certs/ca-certificates.crt
              readOnly: true
          imagePullPolicy: "Always"
      volumes:
        - name: ssl-certs
          hostPath:
            path: "/etc/ssl/certs/ca-bundle.crt"
EOF
```


#### update cluster name
```
sed -i "s#xxx#${CLUSTER_NAME}#" cluster-autoscaler-autodiscover.yaml
```

#### create cluster autoscaler
```
kubectl apply -f cluster-autoscaler-autodiscover.yaml
```
#### add annotation
```
kubectl -n kube-system annotate deployment.apps/cluster-autoscaler cluster-autoscaler.kubernetes.io/safe-to-evict="false"
```
#### update image path
```
kubectl -n kube-system set image deployment.apps/cluster-autoscaler cluster-autoscaler=us.gcr.io/k8s-artifacts-prod/autoscaling/cluster-autoscaler:v1.18.2
```
#### scale down pod
```
kubectl scale --replicas=1 deployment/myapp-deployment
kubectl get pod -n kube-system
```
check cluster-autoscaler-* is Running status.

#### cluster autoscaler logs
```
kubectl -n kube-system logs -f deployment.apps/cluster-autoscaler
```

### 2. load test
```
ALB_URL=$(kubectl get ingress -o json| jq -r '.items[0].status.loadBalancer.ingress[0].hostname')
ab -c 10 -n 2000000 http://${ALB_URL}/index.jsp
```
### 3. monitor HPA
```
kubectl top pod
kubectl get hpa --watch
```
### 4. check nod count
```
kubectl get node
```


## cleanup
```
kubectl delete hpa myapp-deployment
kubectl delete -f cluster-autoscaler-autodiscover.yaml
```